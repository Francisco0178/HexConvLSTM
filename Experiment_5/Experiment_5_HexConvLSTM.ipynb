{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 5:\n",
        "Timestep Reduction to the mean of 2 consecutive hours and timesteps of 24 steps\n",
        "\n",
        "Network: HexConvLSTM"
      ],
      "metadata": {
        "id": "MOe3D01_b6c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adV_JP_iSXtz",
        "outputId": "28740639-5c88-4e67-f48c-c53f40214280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LKjqB17RsAx"
      },
      "outputs": [],
      "source": [
        "# Loading necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(threshold=np.inf, precision=2, linewidth=200)\n",
        "np.set_printoptions(suppress=True, precision=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a first step, we load the raw data from our source."
      ],
      "metadata": {
        "id": "5_cfNVgTSOkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the source path\n",
        "route_folder = \"/content/drive/My Drive/Centro de Transporte/Francisco/2023/Abril 2024/\"\n",
        "\n",
        "# Loading the tensor\n",
        "tensor = np.load(route_folder+'tensor.npy')\n",
        "# 110 original coordinates\n",
        "ori_coords = pd.read_csv(route_folder+'ori_coords.csv')"
      ],
      "metadata": {
        "id": "OcNVmAd4ThkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are going to reduce our time steps by averaging over consecutive 2-hour intervals."
      ],
      "metadata": {
        "id": "_a7WF7mq4NtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if tensor.shape[0] % 2 == 0:\n",
        "    tensor_reshaped = tensor.reshape(-1, 2, tensor.shape[1], tensor.shape[2])\n",
        "    tensor_new = tensor_reshaped.mean(axis=1)"
      ],
      "metadata": {
        "id": "BYPwmKbL9L_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l39NNUci9hOI",
        "outputId": "efb8a377-8364-4810-9e34-409e7591aaa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(942, 44, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have preprocessed our matrices, we will apply min-max scaling normalization to all our steps"
      ],
      "metadata": {
        "id": "uTKzbBZv3UkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "tensor_reshaped = tensor_new.reshape(-1, 15)\n",
        "scaled_tensor = scaler.fit_transform(tensor_reshaped)\n",
        "scaled_tensor = scaled_tensor.reshape(-1, 44, 15)"
      ],
      "metadata": {
        "id": "UDJtPaPO3hhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have normalized our tensor, we divide it into training, validation, and testing sets."
      ],
      "metadata": {
        "id": "z9X6OEIR3sYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_percent = 0.7\n",
        "val_percent = 0.15\n",
        "test_percent = 0.15\n",
        "\n",
        "total_examples = scaled_tensor.shape[0]\n",
        "num_train_examples = int(total_examples * train_percent)\n",
        "num_val_examples = int(total_examples * val_percent)\n",
        "num_test_examples = total_examples - num_train_examples - num_val_examples\n",
        "\n",
        "train_tensor = scaled_tensor[:num_train_examples]\n",
        "val_tensor = scaled_tensor[num_train_examples:num_train_examples+num_val_examples]\n",
        "test_tensor = scaled_tensor[num_train_examples+num_val_examples:]\n",
        "\n",
        "# Add a final dimension of 1 channel; this is necessary to feed it into our network\n",
        "train_tensor = train_tensor.reshape((train_tensor.shape[0], train_tensor.shape[1], train_tensor.shape[2], 1))\n",
        "val_tensor = val_tensor.reshape((val_tensor.shape[0], val_tensor.shape[1], val_tensor.shape[2], 1))\n",
        "test_tensor = test_tensor.reshape((test_tensor.shape[0], test_tensor.shape[1], test_tensor.shape[2], 1))\n",
        "\n",
        "print(train_tensor.shape, val_tensor.shape, test_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBpFWxTv3qv0",
        "outputId": "1ce69cfa-d109-4c15-c38a-a5d1234c5f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(659, 44, 15, 1) (141, 44, 15, 1) (142, 44, 15, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will generate the sequences"
      ],
      "metadata": {
        "id": "GfZTA9Jk4uUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_secuencias(tensor, longitud_secuencia):\n",
        "    secuencias_x = []\n",
        "    secuencias_y = []\n",
        "    for i in range(len(tensor) - longitud_secuencia):\n",
        "        secuencia_x = tensor[i:i+longitud_secuencia]\n",
        "        secuencia_y = tensor[i+longitud_secuencia:i+longitud_secuencia+1]\n",
        "        secuencias_x.append(secuencia_x)\n",
        "        secuencias_y.append(secuencia_y)\n",
        "    return np.array(secuencias_x), np.array(secuencias_y)\n",
        "\n",
        "#  1  2  3   4   5   6   7   8   9   10  11  12\n",
        "# [8][9][10][11][12][13][14][15][16][17][18][19] -> [8]\n",
        "\n",
        "longitud_secuencia = 24\n",
        "\n",
        "x_train, y_train = crear_secuencias(train_tensor, longitud_secuencia)\n",
        "x_val, y_val = crear_secuencias(val_tensor, longitud_secuencia)\n",
        "x_test, y_test = crear_secuencias(test_tensor, longitud_secuencia)\n",
        "\n",
        "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
        "print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))\n",
        "print(\"Validation Dataset Shapes: \" + str(x_test.shape) + \", \" + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvE-iW98381I",
        "outputId": "df9e1512-1146-45bd-f943-da9de959eaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Shapes: (635, 24, 44, 15, 1), (635, 1, 44, 15, 1)\n",
            "Validation Dataset Shapes: (117, 24, 44, 15, 1), (117, 1, 44, 15, 1)\n",
            "Validation Dataset Shapes: (118, 24, 44, 15, 1), (118, 1, 44, 15, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up to this point, we have preprocessed our tensors and they are ready to be fed into our neural network. But before that, we need to define our hexagonal kernel and our network."
      ],
      "metadata": {
        "id": "KIUUb4Vf47_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define our hexagonal kernel"
      ],
      "metadata": {
        "id": "q6gCWlx35adc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hexagonal kernel\n",
        "class HexConstGrid5x3(tf.keras.constraints.Constraint):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def __call__(self, w):\n",
        "        '''\n",
        "        [[0, 1, 0],\n",
        "         [1, 0, 1],\n",
        "         [0, 1, 0],\n",
        "         [1, 0, 1],\n",
        "         [0, 1, 0]]\n",
        "        '''\n",
        "        hexaconst=np.ones(w.shape,dtype=np.float32)\n",
        "        hexaconst[0,0,:,:]=0.0\n",
        "        hexaconst[0,2,:,:]=0.0\n",
        "        hexaconst[1,1,:,:]=0.0\n",
        "        hexaconst[2,0,:,:]=0.0\n",
        "        hexaconst[2,2,:,:]=0.0\n",
        "        hexaconst[3,1,:,:]=0.0\n",
        "        hexaconst[4,0,:,:]=0.0\n",
        "        hexaconst[4,2,:,:]=0.0\n",
        "\n",
        "        return w*hexaconst"
      ],
      "metadata": {
        "id": "pU5SZekP454d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we define our HexConvLSTM network"
      ],
      "metadata": {
        "id": "dKuKXSPQ5S6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = layers.Input(shape=(None, *x_train.shape[2:]))\n",
        "\n",
        "# ConvLSTM2D layer\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=128,\n",
        "    kernel_size=(5, 3),\n",
        "    padding=\"same\",\n",
        "    return_sequences=False,\n",
        "    activation=\"relu\",\n",
        "    kernel_constraint=HexConstGrid5x3()\n",
        ")(inp)\n",
        "\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Conv2D layer\n",
        "x = layers.Conv2D(\n",
        "    filters=1,\n",
        "    kernel_size=(3, 3),\n",
        "    activation=\"relu\",\n",
        "    padding=\"same\"\n",
        ")(x)\n",
        "\n",
        "x = layers.Reshape((1,44,15,1))(x)"
      ],
      "metadata": {
        "id": "_Thb-OR-5Sao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the complete model\n",
        "model = keras.models.Model(inp, x)\n",
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer=keras.optimizers.Adam()\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuMqSYrG5h8D",
        "outputId": "530aa9e0-e6f5-4cc0-bd50-96a25f7a7b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, 44, 15, 1   0         \n",
            "                             )]                                  \n",
            "                                                                 \n",
            " conv_lstm2d (ConvLSTM2D)    (None, 44, 15, 128)       991232    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 44, 15, 128)       512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 44, 15, 1)         1153      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 44, 15, 1)      0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 992897 (3.79 MB)\n",
            "Trainable params: 992641 (3.79 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our network defined, let's train it."
      ],
      "metadata": {
        "id": "O7WzcmQF5nHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some callbacks to improve training.\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
        "\n",
        "# Define modifiable training hyperparameters.\n",
        "epochs = 500\n",
        "batch_size = 64\n",
        "\n",
        "# Fit the model to the training data.\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BxawDce5lbB",
        "outputId": "e8ca46dd-9070-473b-dba3-08f8137d9ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "10/10 [==============================] - 24s 868ms/step - loss: 0.0363 - val_loss: 0.0578 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0046 - val_loss: 0.0577 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0031 - val_loss: 0.0576 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0027 - val_loss: 0.0574 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0025 - val_loss: 0.0573 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0024 - val_loss: 0.0573 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0024 - val_loss: 0.0572 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0023 - val_loss: 0.0571 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0023 - val_loss: 0.0571 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0023 - val_loss: 0.0570 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - 5s 530ms/step - loss: 0.0023 - val_loss: 0.0568 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0023 - val_loss: 0.0566 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0023 - val_loss: 0.0563 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0023 - val_loss: 0.0561 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0023 - val_loss: 0.0556 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - 5s 528ms/step - loss: 0.0022 - val_loss: 0.0555 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0023 - val_loss: 0.0550 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0023 - val_loss: 0.0545 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - 5s 528ms/step - loss: 0.0022 - val_loss: 0.0541 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0533 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - 5s 529ms/step - loss: 0.0022 - val_loss: 0.0528 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0523 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.0022 - val_loss: 0.0513 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0022 - val_loss: 0.0508 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0501 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0500 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0022 - val_loss: 0.0490 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - 5s 520ms/step - loss: 0.0022 - val_loss: 0.0483 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0022 - val_loss: 0.0475 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0468 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.0022 - val_loss: 0.0458 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - 5s 528ms/step - loss: 0.0022 - val_loss: 0.0446 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0440 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0432 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - 5s 529ms/step - loss: 0.0022 - val_loss: 0.0423 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - 5s 538ms/step - loss: 0.0022 - val_loss: 0.0423 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0411 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0394 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0391 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0378 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0022 - val_loss: 0.0368 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0348 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0333 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0324 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - 5s 529ms/step - loss: 0.0022 - val_loss: 0.0313 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0298 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0287 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0276 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0260 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0251 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0239 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0233 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0226 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0208 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0203 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0187 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0176 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0022 - val_loss: 0.0159 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - 5s 531ms/step - loss: 0.0022 - val_loss: 0.0151 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0146 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - 5s 530ms/step - loss: 0.0022 - val_loss: 0.0143 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0131 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0022 - val_loss: 0.0115 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0107 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0096 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0091 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0080 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0064 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0022 - val_loss: 0.0060 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0057 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0053 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0022 - val_loss: 0.0051 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0048 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0054 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0046 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0048 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0022 - val_loss: 0.0046 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0022 - val_loss: 0.0039 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0040 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - 5s 528ms/step - loss: 0.0022 - val_loss: 0.0038 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0037 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0022 - val_loss: 0.0034 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0022 - val_loss: 0.0034 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0022 - val_loss: 0.0032 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0033 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0022 - val_loss: 0.0032 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - 5s 532ms/step - loss: 0.0022 - val_loss: 0.0033 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0022 - val_loss: 0.0033 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0022 - val_loss: 0.0033 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - 5s 529ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - 5s 528ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - 5s 520ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - 5s 520ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - 5s 531ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - 5s 528ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - 5s 533ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - 5s 528ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - 5s 530ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - 5s 529ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - 5s 530ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - 5s 526ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - 5s 532ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - 5s 527ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - 5s 528ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f123a947d00>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the loss"
      ],
      "metadata": {
        "id": "N0XtKp9s-P5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.history.history\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['loss'], label='Training Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "U-GB3gjO5ujD",
        "outputId": "251eba61-0f17-4258-8b89-01fb7bcc91b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's generate the evaluation metrics for the dimensions 44x15, 15x15, and the 110 coordinates."
      ],
      "metadata": {
        "id": "iNovqiYT-jGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_prediction = model.predict(x_train)\n",
        "train_prediction.shape\n",
        "\n",
        "train_prediction_reshaped = train_prediction.reshape(-1, 15)\n",
        "train_prediction_original_scale = scaler.inverse_transform(train_prediction_reshaped)\n",
        "train_prediction_original_scale = train_prediction_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "y_train_reshaped = y_train.reshape(-1, 15)\n",
        "y_train_original_scale = scaler.inverse_transform(y_train_reshaped)\n",
        "y_train_original_scale = y_train_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "val_prediction = model.predict(x_val)\n",
        "\n",
        "val_prediction_reshaped = val_prediction.reshape(-1, 15)\n",
        "val_prediction_original_scale = scaler.inverse_transform(val_prediction_reshaped)\n",
        "val_prediction_original_scale = val_prediction_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "y_val_reshaped = y_val.reshape(-1, 15)\n",
        "y_val_original_scale = scaler.inverse_transform(y_val_reshaped)\n",
        "y_val_original_scale = y_val_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "test_prediction = model.predict(x_test)\n",
        "\n",
        "test_prediction_reshaped = test_prediction.reshape(-1, 15)\n",
        "test_prediction_original_scale = scaler.inverse_transform(test_prediction_reshaped)\n",
        "test_prediction_original_scale = test_prediction_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "y_test_reshaped = y_test.reshape(-1, 15)\n",
        "y_test_original_scale = scaler.inverse_transform(y_test_reshaped)\n",
        "y_test_original_scale = y_test_original_scale.reshape(-1, 44, 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIX-v5Tn-VYJ",
        "outputId": "9166f37c-d510-4bfc-8600-89fbdc955d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 2s 95ms/step\n",
            "4/4 [==============================] - 0s 140ms/step\n",
            "4/4 [==============================] - 0s 131ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def calcular_metricas_3d(original_tensor, prediccion_tensor):\n",
        "\n",
        "    sum_mae, sum_mse, sum_rmse, sum_r2 = 0, 0, 0, 0\n",
        "\n",
        "    for i in range(original_tensor.shape[0]):\n",
        "        mae = mean_absolute_error(original_tensor[i], prediccion_tensor[i])\n",
        "        mse = mean_squared_error(original_tensor[i], prediccion_tensor[i])\n",
        "        rmse = np.sqrt(mse)\n",
        "        r2 = r2_score(original_tensor[i].flatten(), prediccion_tensor[i].flatten())\n",
        "\n",
        "        sum_mae += mae\n",
        "        sum_mse += mse\n",
        "        sum_rmse += rmse\n",
        "        sum_r2 += r2\n",
        "\n",
        "    avg_mae = sum_mae / original_tensor.shape[0]\n",
        "    avg_mse = sum_mse / original_tensor.shape[0]\n",
        "    avg_rmse = sum_rmse / original_tensor.shape[0]\n",
        "    avg_r2 = sum_r2 / original_tensor.shape[0]\n",
        "\n",
        "    return avg_mae, avg_mse, avg_rmse, avg_r2"
      ],
      "metadata": {
        "id": "ATmsGRat_EWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for 44x15"
      ],
      "metadata": {
        "id": "FR2WvelW_MOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae, mse, rmse, r2 = calcular_metricas_3d(y_train_original_scale, train_prediction_original_scale)\n",
        "\n",
        "print(\"Training:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(y_val_original_scale, val_prediction_original_scale)\n",
        "\n",
        "print(\"Validation:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(y_test_original_scale, test_prediction_original_scale)\n",
        "\n",
        "print(\"Test:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCkjRYsc_K7r",
        "outputId": "84d6891c-b3a3-40d9-85a3-04c10f6a6a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Average MAE: 1.472\n",
            "Average MSE: 15.056\n",
            "Average RMSE: 3.808\n",
            "Average R^2: 0.917\n",
            "\n",
            "Validation:\n",
            "Average MAE: 1.848\n",
            "Average MSE: 21.270\n",
            "Average RMSE: 4.560\n",
            "Average R^2: 0.906\n",
            "\n",
            "Test:\n",
            "Average MAE: 1.886\n",
            "Average MSE: 21.374\n",
            "Average RMSE: 4.585\n",
            "Average R^2: 0.905\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for 15x15"
      ],
      "metadata": {
        "id": "j-MP14If_f4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess(arr):\n",
        "  unshifted_matrix = np.empty_like(arr)\n",
        "  for i in range(arr.shape[1]):\n",
        "      n = i\n",
        "      unshifted_matrix[:, i] = np.concatenate((arr[-n:, i], arr[:-n, i]))\n",
        "\n",
        "  unpadded_matrix = unshifted_matrix[14:, :]\n",
        "  downsampled_matrix = unpadded_matrix[::2]\n",
        "\n",
        "  return downsampled_matrix\n",
        "\n",
        "# Training:\n",
        "# Postprocess originals\n",
        "postprocessed_originals_train = []\n",
        "for i in range(y_train_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(y_train_original_scale[i])\n",
        "    postprocessed_originals_train.append(postprocessed_matrix)\n",
        "postprocessed_original_arr_train = np.array(postprocessed_originals_train)\n",
        "\n",
        "# Postprocess predictions\n",
        "postprocessed_predictions_train = []\n",
        "for i in range(train_prediction_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(train_prediction_original_scale[i])\n",
        "    postprocessed_predictions_train.append(postprocessed_matrix)\n",
        "\n",
        "postprocessed_predictions_arr_train = np.array(postprocessed_predictions_train)\n",
        "\n",
        "# Validation:\n",
        "# Postprocess originals\n",
        "postprocessed_originals_val = []\n",
        "for i in range(y_val_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(y_val_original_scale[i])\n",
        "    postprocessed_originals_val.append(postprocessed_matrix)\n",
        "postprocessed_original_arr_val = np.array(postprocessed_originals_val)\n",
        "\n",
        "# Postprocess predictions\n",
        "postprocessed_predictions_val = []\n",
        "for i in range(val_prediction_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(val_prediction_original_scale[i])\n",
        "    postprocessed_predictions_val.append(postprocessed_matrix)\n",
        "\n",
        "postprocessed_predictions_arr_val = np.array(postprocessed_predictions_val)\n",
        "\n",
        "# Testing:\n",
        "# Postprocess originals\n",
        "postprocessed_originals_test = []\n",
        "for i in range(y_test_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(y_test_original_scale[i])\n",
        "    postprocessed_originals_test.append(postprocessed_matrix)\n",
        "postprocessed_original_arr_test = np.array(postprocessed_originals_test)\n",
        "\n",
        "# Postprocess predictions\n",
        "postprocessed_predictions_test = []\n",
        "for i in range(test_prediction_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(test_prediction_original_scale[i])\n",
        "    postprocessed_predictions_test.append(postprocessed_matrix)\n",
        "\n",
        "postprocessed_predictions_arr_test = np.array(postprocessed_predictions_test)\n",
        "\n",
        "# Calcular las mtricas promedio\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(postprocessed_original_arr_train, postprocessed_predictions_arr_train)\n",
        "\n",
        "print(\"Training:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(postprocessed_original_arr_val, postprocessed_predictions_arr_val)\n",
        "\n",
        "print(\"Validation:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(postprocessed_original_arr_test, postprocessed_predictions_arr_test)\n",
        "\n",
        "print(\"Test:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXc8wkPw_awT",
        "outputId": "d146ba2f-b1c7-479c-c831-4941479d10cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Average MAE: 2.157\n",
            "Average MSE: 22.081\n",
            "Average RMSE: 4.612\n",
            "Average R^2: 0.896\n",
            "\n",
            "Validation:\n",
            "Average MAE: 2.709\n",
            "Average MSE: 31.264\n",
            "Average RMSE: 5.528\n",
            "Average R^2: 0.881\n",
            "\n",
            "Test:\n",
            "Average MAE: 2.766\n",
            "Average MSE: 31.409\n",
            "Average RMSE: 5.558\n",
            "Average R^2: 0.881\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for 110 coordinates"
      ],
      "metadata": {
        "id": "XWCqTLps_2w3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We convert the data into dataframes and combine actual vs. predictions\n",
        "def array_to_dataframe(arr):\n",
        "    ids = []\n",
        "    is_list = []\n",
        "    js_list = []\n",
        "    velocidades = []\n",
        "\n",
        "    for id in range(arr.shape[0]):\n",
        "        for i in range(arr.shape[1]):\n",
        "            for j in range(arr.shape[2]):\n",
        "                ids.append(id)\n",
        "                is_list.append(i)\n",
        "                js_list.append(j)\n",
        "                velocidades.append(arr[id, i, j])\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'id': ids,\n",
        "        'i': is_list,\n",
        "        'j': js_list,\n",
        "        'speed': velocidades\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "# Training:\n",
        "df_actuals_train = array_to_dataframe(postprocessed_original_arr_train)\n",
        "df_preds_train = array_to_dataframe(postprocessed_predictions_arr_train)\n",
        "\n",
        "df_original_train = df_actuals_train.rename(columns={'speed': 'speed_actual'})\n",
        "df_predictions_train = df_preds_train.rename(columns={'speed': 'speed_predicted'})\n",
        "\n",
        "df_results_train = pd.merge(df_original_train, df_predictions_train, on=['id','i', 'j'], how='inner')\n",
        "# ----------------------------#\n",
        "\n",
        "# Validation:\n",
        "df_actuals_val = array_to_dataframe(postprocessed_original_arr_val)\n",
        "df_preds_val = array_to_dataframe(postprocessed_predictions_arr_val)\n",
        "\n",
        "df_original_val = df_actuals_val.rename(columns={'speed': 'speed_actual'})\n",
        "df_predictions_val = df_preds_val.rename(columns={'speed': 'speed_predicted'})\n",
        "\n",
        "df_results_val = pd.merge(df_original_val, df_predictions_val, on=['id','i', 'j'], how='inner')\n",
        "# ----------------------------#\n",
        "\n",
        "# Test:\n",
        "df_actuals_test = array_to_dataframe(postprocessed_original_arr_test)\n",
        "df_preds_test = array_to_dataframe(postprocessed_predictions_arr_test)\n",
        "\n",
        "df_original_test = df_actuals_test.rename(columns={'speed': 'speed_actual'})\n",
        "df_predictions_test = df_preds_test.rename(columns={'speed': 'speed_predicted'})\n",
        "\n",
        "df_results_test = pd.merge(df_original_test, df_predictions_test, on=['id','i', 'j'], how='inner')\n",
        "# ----------------------------#\n",
        "\n",
        "\n",
        "results_110_train = pd.merge(ori_coords, df_results_train, on=['i','j'])\n",
        "results_110_val = pd.merge(ori_coords, df_results_val, on=['i','j'])\n",
        "results_110_test = pd.merge(ori_coords, df_results_test, on=['i','j'])\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from math import sqrt\n",
        "\n",
        "def calculate_metrics(df):\n",
        "    y_true = df['speed_actual']\n",
        "    y_pred = df['speed_predicted']\n",
        "\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    smape = 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))\n",
        "    maaape = np.mean(np.arctan(np.abs((y_true - y_pred) / y_true))) * 100\n",
        "\n",
        "    return mae, mse, rmse, r2, mape, smape, maaape\n",
        "\n",
        "\n",
        "mae, mse, rmse, r2, mape, smape, maaape = calculate_metrics(results_110_train)\n",
        "\n",
        "print(\"Training:\")\n",
        "print(\"----------\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(f\"Average MAPE: {mape:.3f}\")\n",
        "print(f\"Average SMAPE: {smape:.3f}\")\n",
        "print(f\"Average MAAPE: {maaape:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2, mape, smape, maaape = calculate_metrics(results_110_val)\n",
        "\n",
        "print(\"Validation:\")\n",
        "print(\"----------\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(f\"Average MAPE: {mape:.3f}\")\n",
        "print(f\"Average SMAPE: {smape:.3f}\")\n",
        "print(f\"Average MAAPE: {maaape:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2, mape, smape, maaape = calculate_metrics(results_110_test)\n",
        "\n",
        "print(\"Testing:\")\n",
        "print(\"----------\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(f\"Average MAPE: {mape:.3f}\")\n",
        "print(f\"Average SMAPE: {smape:.3f}\")\n",
        "print(f\"Average MAAPE: {maaape:.3f}\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag4h2kCU_0zh",
        "outputId": "0f680506-edc8-44b5-f977-b698211ec9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "----------\n",
            "Average MAE: 4.266\n",
            "Average MSE: 44.291\n",
            "Average RMSE: 6.655\n",
            "Average R^2: 0.642\n",
            "Average MAPE: inf\n",
            "Average SMAPE: 17.796\n",
            "Average MAAPE: 18.117\n",
            "\n",
            "Validation:\n",
            "----------\n",
            "Average MAE: 5.335\n",
            "Average MSE: 62.564\n",
            "Average RMSE: 7.910\n",
            "Average R^2: 0.615\n",
            "Average MAPE: inf\n",
            "Average SMAPE: 20.933\n",
            "Average MAAPE: 21.114\n",
            "\n",
            "Testing:\n",
            "----------\n",
            "Average MAE: 5.423\n",
            "Average MSE: 62.753\n",
            "Average RMSE: 7.922\n",
            "Average R^2: 0.619\n",
            "Average MAPE: inf\n",
            "Average SMAPE: 21.410\n",
            "Average MAAPE: 21.694\n",
            "\n"
          ]
        }
      ]
    }
  ]
}