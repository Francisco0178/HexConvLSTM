{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 4:\n",
        "Timestep Reduction to the mean of 3 consecutive hours and timesteps of 24 steps\n",
        "\n",
        "Network: HexConvLSTM"
      ],
      "metadata": {
        "id": "MOe3D01_b6c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adV_JP_iSXtz",
        "outputId": "e5e059ce-d00a-4332-c7db-14fc37a501fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LKjqB17RsAx"
      },
      "outputs": [],
      "source": [
        "# Loading necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(threshold=np.inf, precision=2, linewidth=200)\n",
        "np.set_printoptions(suppress=True, precision=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a first step, we load the raw data from our source."
      ],
      "metadata": {
        "id": "5_cfNVgTSOkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the source path\n",
        "route_folder = \"/content/drive/My Drive/Centro de Transporte/Francisco/2023/Abril 2024/\"\n",
        "\n",
        "# Loading the tensor\n",
        "tensor = np.load(route_folder+'tensor.npy')\n",
        "# 110 original coordinates\n",
        "ori_coords = pd.read_csv(route_folder+'ori_coords.csv')"
      ],
      "metadata": {
        "id": "OcNVmAd4ThkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are going to reduce our time steps by averaging over consecutive 3-hour intervals."
      ],
      "metadata": {
        "id": "_a7WF7mq4NtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if tensor.shape[0] % 3 == 0:\n",
        "    tensor_reshaped = tensor.reshape(-1, 3, tensor.shape[1], tensor.shape[2])\n",
        "    tensor_new = tensor_reshaped.mean(axis=1)"
      ],
      "metadata": {
        "id": "BYPwmKbL9L_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l39NNUci9hOI",
        "outputId": "6186ab5a-7c90-4ecf-8752-3f5f1aeb5bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(628, 44, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have preprocessed our matrices, we will apply min-max scaling normalization to all our steps"
      ],
      "metadata": {
        "id": "uTKzbBZv3UkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "tensor_reshaped = tensor_new.reshape(-1, 15)\n",
        "scaled_tensor = scaler.fit_transform(tensor_reshaped)\n",
        "scaled_tensor = scaled_tensor.reshape(-1, 44, 15)"
      ],
      "metadata": {
        "id": "UDJtPaPO3hhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have normalized our tensor, we divide it into training, validation, and testing sets."
      ],
      "metadata": {
        "id": "z9X6OEIR3sYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_percent = 0.7\n",
        "val_percent = 0.15\n",
        "test_percent = 0.15\n",
        "\n",
        "total_examples = scaled_tensor.shape[0]\n",
        "num_train_examples = int(total_examples * train_percent)\n",
        "num_val_examples = int(total_examples * val_percent)\n",
        "num_test_examples = total_examples - num_train_examples - num_val_examples\n",
        "\n",
        "train_tensor = scaled_tensor[:num_train_examples]\n",
        "val_tensor = scaled_tensor[num_train_examples:num_train_examples+num_val_examples]\n",
        "test_tensor = scaled_tensor[num_train_examples+num_val_examples:]\n",
        "\n",
        "# Add a final dimension of 1 channel; this is necessary to feed it into our network\n",
        "train_tensor = train_tensor.reshape((train_tensor.shape[0], train_tensor.shape[1], train_tensor.shape[2], 1))\n",
        "val_tensor = val_tensor.reshape((val_tensor.shape[0], val_tensor.shape[1], val_tensor.shape[2], 1))\n",
        "test_tensor = test_tensor.reshape((test_tensor.shape[0], test_tensor.shape[1], test_tensor.shape[2], 1))\n",
        "\n",
        "print(train_tensor.shape, val_tensor.shape, test_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBpFWxTv3qv0",
        "outputId": "38443072-8863-43d2-d8f8-60ffbc338330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(439, 44, 15, 1) (94, 44, 15, 1) (95, 44, 15, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will generate the sequences"
      ],
      "metadata": {
        "id": "GfZTA9Jk4uUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_secuencias(tensor, longitud_secuencia):\n",
        "    secuencias_x = []\n",
        "    secuencias_y = []\n",
        "    for i in range(len(tensor) - longitud_secuencia):\n",
        "        secuencia_x = tensor[i:i+longitud_secuencia]\n",
        "        secuencia_y = tensor[i+longitud_secuencia:i+longitud_secuencia+1]\n",
        "        secuencias_x.append(secuencia_x)\n",
        "        secuencias_y.append(secuencia_y)\n",
        "    return np.array(secuencias_x), np.array(secuencias_y)\n",
        "\n",
        "#  1  2  3   4   5   6   7   8   9   10  11  12\n",
        "# [8][9][10][11][12][13][14][15][16][17][18][19] -> [8]\n",
        "\n",
        "longitud_secuencia = 24\n",
        "\n",
        "x_train, y_train = crear_secuencias(train_tensor, longitud_secuencia)\n",
        "x_val, y_val = crear_secuencias(val_tensor, longitud_secuencia)\n",
        "x_test, y_test = crear_secuencias(test_tensor, longitud_secuencia)\n",
        "\n",
        "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
        "print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))\n",
        "print(\"Validation Dataset Shapes: \" + str(x_test.shape) + \", \" + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvE-iW98381I",
        "outputId": "647660b0-cb24-4c07-9907-5aac9f1fcc6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Shapes: (415, 24, 44, 15, 1), (415, 1, 44, 15, 1)\n",
            "Validation Dataset Shapes: (70, 24, 44, 15, 1), (70, 1, 44, 15, 1)\n",
            "Validation Dataset Shapes: (71, 24, 44, 15, 1), (71, 1, 44, 15, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up to this point, we have preprocessed our tensors and they are ready to be fed into our neural network. But before that, we need to define our hexagonal kernel and our network."
      ],
      "metadata": {
        "id": "KIUUb4Vf47_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define our hexagonal kernel"
      ],
      "metadata": {
        "id": "q6gCWlx35adc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hexagonal kernel\n",
        "class HexConstGrid5x3(tf.keras.constraints.Constraint):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def __call__(self, w):\n",
        "        '''\n",
        "        [[0, 1, 0],\n",
        "         [1, 0, 1],\n",
        "         [0, 1, 0],\n",
        "         [1, 0, 1],\n",
        "         [0, 1, 0]]\n",
        "        '''\n",
        "        hexaconst=np.ones(w.shape,dtype=np.float32)\n",
        "        hexaconst[0,0,:,:]=0.0\n",
        "        hexaconst[0,2,:,:]=0.0\n",
        "        hexaconst[1,1,:,:]=0.0\n",
        "        hexaconst[2,0,:,:]=0.0\n",
        "        hexaconst[2,2,:,:]=0.0\n",
        "        hexaconst[3,1,:,:]=0.0\n",
        "        hexaconst[4,0,:,:]=0.0\n",
        "        hexaconst[4,2,:,:]=0.0\n",
        "\n",
        "        return w*hexaconst"
      ],
      "metadata": {
        "id": "pU5SZekP454d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we define our HexConvLSTM network"
      ],
      "metadata": {
        "id": "dKuKXSPQ5S6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = layers.Input(shape=(None, *x_train.shape[2:]))\n",
        "\n",
        "# ConvLSTM2D layer\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=128,\n",
        "    kernel_size=(5, 3),\n",
        "    padding=\"same\",\n",
        "    return_sequences=False,\n",
        "    activation=\"relu\",\n",
        "    kernel_constraint=HexConstGrid5x3()\n",
        ")(inp)\n",
        "\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Conv2D layer\n",
        "x = layers.Conv2D(\n",
        "    filters=1,\n",
        "    kernel_size=(3, 3),\n",
        "    activation=\"relu\",\n",
        "    padding=\"same\"\n",
        ")(x)\n",
        "\n",
        "x = layers.Reshape((1,44,15,1))(x)"
      ],
      "metadata": {
        "id": "_Thb-OR-5Sao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the complete model\n",
        "model = keras.models.Model(inp, x)\n",
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer=keras.optimizers.Adam()\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuMqSYrG5h8D",
        "outputId": "4e1e2663-a1d2-441f-b876-866a6214a729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, 44, 15, 1   0         \n",
            "                             )]                                  \n",
            "                                                                 \n",
            " conv_lstm2d (ConvLSTM2D)    (None, 44, 15, 128)       991232    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 44, 15, 128)       512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 44, 15, 1)         1153      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 44, 15, 1)      0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 992897 (3.79 MB)\n",
            "Trainable params: 992641 (3.79 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our network defined, let's train it."
      ],
      "metadata": {
        "id": "O7WzcmQF5nHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some callbacks to improve training.\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
        "\n",
        "# Define modifiable training hyperparameters.\n",
        "epochs = 500\n",
        "batch_size = 64\n",
        "\n",
        "# Fit the model to the training data.\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BxawDce5lbB",
        "outputId": "0b86e11d-218d-4d61-ca66-1d09b673e8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "7/7 [==============================] - 13s 593ms/step - loss: 0.0728 - val_loss: 0.0773 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0134 - val_loss: 0.0774 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0059 - val_loss: 0.0774 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0038 - val_loss: 0.0774 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0032 - val_loss: 0.0774 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0029 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "7/7 [==============================] - 3s 495ms/step - loss: 0.0027 - val_loss: 0.0771 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0026 - val_loss: 0.0771 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0025 - val_loss: 0.0770 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0025 - val_loss: 0.0769 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0024 - val_loss: 0.0769 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0024 - val_loss: 0.0768 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0023 - val_loss: 0.0768 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "7/7 [==============================] - 4s 535ms/step - loss: 0.0023 - val_loss: 0.0767 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "7/7 [==============================] - 4s 546ms/step - loss: 0.0023 - val_loss: 0.0767 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0023 - val_loss: 0.0767 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0023 - val_loss: 0.0766 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0023 - val_loss: 0.0765 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0023 - val_loss: 0.0763 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0023 - val_loss: 0.0761 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0023 - val_loss: 0.0759 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "7/7 [==============================] - 3s 494ms/step - loss: 0.0023 - val_loss: 0.0758 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0022 - val_loss: 0.0754 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0751 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "7/7 [==============================] - 4s 508ms/step - loss: 0.0022 - val_loss: 0.0742 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "7/7 [==============================] - 3s 494ms/step - loss: 0.0022 - val_loss: 0.0741 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0022 - val_loss: 0.0735 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0022 - val_loss: 0.0731 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0022 - val_loss: 0.0723 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "7/7 [==============================] - 4s 512ms/step - loss: 0.0022 - val_loss: 0.0719 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0714 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0712 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0022 - val_loss: 0.0702 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0022 - val_loss: 0.0688 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0023 - val_loss: 0.0691 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0687 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0022 - val_loss: 0.0676 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0022 - val_loss: 0.0661 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0652 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0022 - val_loss: 0.0647 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0022 - val_loss: 0.0640 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0022 - val_loss: 0.0638 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0022 - val_loss: 0.0625 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0618 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0022 - val_loss: 0.0610 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0022 - val_loss: 0.0605 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0595 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0582 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "7/7 [==============================] - 3s 497ms/step - loss: 0.0022 - val_loss: 0.0580 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0022 - val_loss: 0.0572 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0022 - val_loss: 0.0550 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0022 - val_loss: 0.0543 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0022 - val_loss: 0.0540 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0535 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "7/7 [==============================] - 3s 491ms/step - loss: 0.0022 - val_loss: 0.0524 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0022 - val_loss: 0.0502 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0022 - val_loss: 0.0499 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0022 - val_loss: 0.0499 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0487 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0022 - val_loss: 0.0458 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0022 - val_loss: 0.0445 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0022 - val_loss: 0.0444 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0022 - val_loss: 0.0441 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "7/7 [==============================] - 4s 516ms/step - loss: 0.0021 - val_loss: 0.0422 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "7/7 [==============================] - 4s 511ms/step - loss: 0.0021 - val_loss: 0.0409 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0410 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0393 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "7/7 [==============================] - 3s 494ms/step - loss: 0.0021 - val_loss: 0.0375 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "7/7 [==============================] - 4s 508ms/step - loss: 0.0021 - val_loss: 0.0371 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0354 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0346 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "7/7 [==============================] - 3s 493ms/step - loss: 0.0021 - val_loss: 0.0331 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0312 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0319 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0299 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0021 - val_loss: 0.0282 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "7/7 [==============================] - 4s 508ms/step - loss: 0.0022 - val_loss: 0.0272 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "7/7 [==============================] - 4s 508ms/step - loss: 0.0021 - val_loss: 0.0269 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "7/7 [==============================] - 3s 496ms/step - loss: 0.0021 - val_loss: 0.0253 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "7/7 [==============================] - 4s 512ms/step - loss: 0.0021 - val_loss: 0.0241 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0232 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0226 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0209 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "7/7 [==============================] - 3s 493ms/step - loss: 0.0021 - val_loss: 0.0202 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "7/7 [==============================] - 4s 508ms/step - loss: 0.0021 - val_loss: 0.0175 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "7/7 [==============================] - 3s 485ms/step - loss: 0.0021 - val_loss: 0.0182 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "7/7 [==============================] - 3s 491ms/step - loss: 0.0021 - val_loss: 0.0168 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0181 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0022 - val_loss: 0.0146 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "7/7 [==============================] - 4s 508ms/step - loss: 0.0021 - val_loss: 0.0157 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "7/7 [==============================] - 3s 495ms/step - loss: 0.0021 - val_loss: 0.0134 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0135 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0121 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0123 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "7/7 [==============================] - 4s 513ms/step - loss: 0.0021 - val_loss: 0.0111 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0095 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0108 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0088 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0021 - val_loss: 0.0085 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0094 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "7/7 [==============================] - 4s 508ms/step - loss: 0.0022 - val_loss: 0.0073 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0021 - val_loss: 0.0077 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "7/7 [==============================] - 4s 508ms/step - loss: 0.0021 - val_loss: 0.0070 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0064 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "7/7 [==============================] - 3s 493ms/step - loss: 0.0021 - val_loss: 0.0065 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0022 - val_loss: 0.0058 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0050 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0054 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "7/7 [==============================] - 3s 491ms/step - loss: 0.0021 - val_loss: 0.0049 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0046 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0046 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0046 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "7/7 [==============================] - 3s 493ms/step - loss: 0.0022 - val_loss: 0.0041 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0022 - val_loss: 0.0038 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0022 - val_loss: 0.0048 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0037 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0021 - val_loss: 0.0040 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0038 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0040 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0035 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0021 - val_loss: 0.0036 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0038 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0033 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0036 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0021 - val_loss: 0.0034 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "7/7 [==============================] - 4s 508ms/step - loss: 0.0021 - val_loss: 0.0033 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "7/7 [==============================] - 3s 491ms/step - loss: 0.0021 - val_loss: 0.0036 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "7/7 [==============================] - 3s 496ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 131/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0033 - lr: 1.0000e-04\n",
            "Epoch 132/500\n",
            "7/7 [==============================] - 4s 509ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 133/500\n",
            "7/7 [==============================] - 3s 491ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 134/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 135/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 136/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-05\n",
            "Epoch 137/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 138/500\n",
            "7/7 [==============================] - 4s 510ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 139/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 140/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 141/500\n",
            "7/7 [==============================] - 3s 494ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 142/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 143/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 144/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 145/500\n",
            "7/7 [==============================] - 3s 495ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 146/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 147/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 148/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 149/500\n",
            "7/7 [==============================] - 3s 491ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 150/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 151/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 152/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 153/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 154/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 155/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 156/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 157/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 158/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 159/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 160/500\n",
            "7/7 [==============================] - 3s 494ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 161/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 162/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 163/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 164/500\n",
            "7/7 [==============================] - 3s 497ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 165/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 166/500\n",
            "7/7 [==============================] - 4s 509ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 167/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 168/500\n",
            "7/7 [==============================] - 4s 516ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 169/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 170/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 171/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 172/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 173/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 174/500\n",
            "7/7 [==============================] - 4s 507ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 175/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 176/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 177/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 178/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 179/500\n",
            "7/7 [==============================] - 3s 491ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 180/500\n",
            "7/7 [==============================] - 3s 491ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 181/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 182/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 183/500\n",
            "7/7 [==============================] - 3s 498ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 184/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 185/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 186/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 187/500\n",
            "7/7 [==============================] - 3s 494ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 188/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 189/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 190/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 191/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 192/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 193/500\n",
            "7/7 [==============================] - 3s 485ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 194/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 195/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 196/500\n",
            "7/7 [==============================] - 3s 485ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 197/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 198/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 199/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 200/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 201/500\n",
            "7/7 [==============================] - 4s 510ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 202/500\n",
            "7/7 [==============================] - 3s 493ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 203/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 204/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 205/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 206/500\n",
            "7/7 [==============================] - 3s 494ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 207/500\n",
            "7/7 [==============================] - 3s 485ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 208/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 209/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 210/500\n",
            "7/7 [==============================] - 3s 492ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 211/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 212/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 213/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 214/500\n",
            "7/7 [==============================] - 3s 491ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 215/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 216/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-21\n",
            "Epoch 217/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-21\n",
            "Epoch 218/500\n",
            "7/7 [==============================] - 3s 491ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-21\n",
            "Epoch 219/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-21\n",
            "Epoch 220/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-21\n",
            "Epoch 221/500\n",
            "7/7 [==============================] - 3s 491ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-22\n",
            "Epoch 222/500\n",
            "7/7 [==============================] - 4s 509ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-22\n",
            "Epoch 223/500\n",
            "7/7 [==============================] - 4s 507ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-22\n",
            "Epoch 224/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-22\n",
            "Epoch 225/500\n",
            "7/7 [==============================] - 3s 496ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-22\n",
            "Epoch 226/500\n",
            "7/7 [==============================] - 3s 485ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-23\n",
            "Epoch 227/500\n",
            "7/7 [==============================] - 3s 486ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-23\n",
            "Epoch 228/500\n",
            "7/7 [==============================] - 3s 487ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-23\n",
            "Epoch 229/500\n",
            "7/7 [==============================] - 3s 494ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-23\n",
            "Epoch 230/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-23\n",
            "Epoch 231/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-24\n",
            "Epoch 232/500\n",
            "7/7 [==============================] - 3s 488ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-24\n",
            "Epoch 233/500\n",
            "7/7 [==============================] - 3s 490ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-24\n",
            "Epoch 234/500\n",
            "7/7 [==============================] - 3s 489ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-24\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c4a6f069660>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the loss"
      ],
      "metadata": {
        "id": "N0XtKp9s-P5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.history.history\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['loss'], label='Training Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-GB3gjO5ujD",
        "outputId": "cdc5899c-7885-4d9a-8753-5ca85acb24b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's generate the evaluation metrics for the dimensions 44x15, 15x15, and the 110 coordinates."
      ],
      "metadata": {
        "id": "iNovqiYT-jGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_prediction = model.predict(x_train)\n",
        "train_prediction.shape\n",
        "\n",
        "train_prediction_reshaped = train_prediction.reshape(-1, 15)\n",
        "train_prediction_original_scale = scaler.inverse_transform(train_prediction_reshaped)\n",
        "train_prediction_original_scale = train_prediction_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "y_train_reshaped = y_train.reshape(-1, 15)\n",
        "y_train_original_scale = scaler.inverse_transform(y_train_reshaped)\n",
        "y_train_original_scale = y_train_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "val_prediction = model.predict(x_val)\n",
        "\n",
        "val_prediction_reshaped = val_prediction.reshape(-1, 15)\n",
        "val_prediction_original_scale = scaler.inverse_transform(val_prediction_reshaped)\n",
        "val_prediction_original_scale = val_prediction_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "y_val_reshaped = y_val.reshape(-1, 15)\n",
        "y_val_original_scale = scaler.inverse_transform(y_val_reshaped)\n",
        "y_val_original_scale = y_val_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "test_prediction = model.predict(x_test)\n",
        "\n",
        "test_prediction_reshaped = test_prediction.reshape(-1, 15)\n",
        "test_prediction_original_scale = scaler.inverse_transform(test_prediction_reshaped)\n",
        "test_prediction_original_scale = test_prediction_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "y_test_reshaped = y_test.reshape(-1, 15)\n",
        "y_test_original_scale = scaler.inverse_transform(y_test_reshaped)\n",
        "y_test_original_scale = y_test_original_scale.reshape(-1, 44, 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIX-v5Tn-VYJ",
        "outputId": "ddf60206-dc93-4a98-ea4a-9fdde0095a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 1s 81ms/step\n",
            "3/3 [==============================] - 0s 84ms/step\n",
            "3/3 [==============================] - 0s 130ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def calcular_metricas_3d(original_tensor, prediccion_tensor):\n",
        "\n",
        "    sum_mae, sum_mse, sum_rmse, sum_r2 = 0, 0, 0, 0\n",
        "\n",
        "    for i in range(original_tensor.shape[0]):\n",
        "        mae = mean_absolute_error(original_tensor[i], prediccion_tensor[i])\n",
        "        mse = mean_squared_error(original_tensor[i], prediccion_tensor[i])\n",
        "        rmse = np.sqrt(mse)\n",
        "        r2 = r2_score(original_tensor[i].flatten(), prediccion_tensor[i].flatten())\n",
        "\n",
        "        sum_mae += mae\n",
        "        sum_mse += mse\n",
        "        sum_rmse += rmse\n",
        "        sum_r2 += r2\n",
        "\n",
        "    avg_mae = sum_mae / original_tensor.shape[0]\n",
        "    avg_mse = sum_mse / original_tensor.shape[0]\n",
        "    avg_rmse = sum_rmse / original_tensor.shape[0]\n",
        "    avg_r2 = sum_r2 / original_tensor.shape[0]\n",
        "\n",
        "    return avg_mae, avg_mse, avg_rmse, avg_r2"
      ],
      "metadata": {
        "id": "ATmsGRat_EWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for 44x15"
      ],
      "metadata": {
        "id": "FR2WvelW_MOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae, mse, rmse, r2 = calcular_metricas_3d(y_train_original_scale, train_prediction_original_scale)\n",
        "\n",
        "print(\"Training:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(y_val_original_scale, val_prediction_original_scale)\n",
        "\n",
        "print(\"Validation:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(y_test_original_scale, test_prediction_original_scale)\n",
        "\n",
        "print(\"Test:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCkjRYsc_K7r",
        "outputId": "5c4cc241-e45f-4a1d-8b0c-8962c9c2f7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Average MAE: 1.266\n",
            "Average MSE: 10.422\n",
            "Average RMSE: 3.176\n",
            "Average R^2: 0.941\n",
            "\n",
            "Validation:\n",
            "Average MAE: 1.590\n",
            "Average MSE: 14.903\n",
            "Average RMSE: 3.827\n",
            "Average R^2: 0.932\n",
            "\n",
            "Test:\n",
            "Average MAE: 1.613\n",
            "Average MSE: 15.322\n",
            "Average RMSE: 3.871\n",
            "Average R^2: 0.931\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for 15x15"
      ],
      "metadata": {
        "id": "j-MP14If_f4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess(arr):\n",
        "  unshifted_matrix = np.empty_like(arr)\n",
        "  for i in range(arr.shape[1]):\n",
        "      n = i\n",
        "      unshifted_matrix[:, i] = np.concatenate((arr[-n:, i], arr[:-n, i]))\n",
        "\n",
        "  unpadded_matrix = unshifted_matrix[14:, :]\n",
        "  downsampled_matrix = unpadded_matrix[::2]\n",
        "\n",
        "  return downsampled_matrix\n",
        "\n",
        "# Training:\n",
        "# Postprocess originals\n",
        "postprocessed_originals_train = []\n",
        "for i in range(y_train_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(y_train_original_scale[i])\n",
        "    postprocessed_originals_train.append(postprocessed_matrix)\n",
        "postprocessed_original_arr_train = np.array(postprocessed_originals_train)\n",
        "\n",
        "# Postprocess predictions\n",
        "postprocessed_predictions_train = []\n",
        "for i in range(train_prediction_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(train_prediction_original_scale[i])\n",
        "    postprocessed_predictions_train.append(postprocessed_matrix)\n",
        "\n",
        "postprocessed_predictions_arr_train = np.array(postprocessed_predictions_train)\n",
        "\n",
        "# Validation:\n",
        "# Postprocess originals\n",
        "postprocessed_originals_val = []\n",
        "for i in range(y_val_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(y_val_original_scale[i])\n",
        "    postprocessed_originals_val.append(postprocessed_matrix)\n",
        "postprocessed_original_arr_val = np.array(postprocessed_originals_val)\n",
        "\n",
        "# Postprocess predictions\n",
        "postprocessed_predictions_val = []\n",
        "for i in range(val_prediction_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(val_prediction_original_scale[i])\n",
        "    postprocessed_predictions_val.append(postprocessed_matrix)\n",
        "\n",
        "postprocessed_predictions_arr_val = np.array(postprocessed_predictions_val)\n",
        "\n",
        "# Testing:\n",
        "# Postprocess originals\n",
        "postprocessed_originals_test = []\n",
        "for i in range(y_test_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(y_test_original_scale[i])\n",
        "    postprocessed_originals_test.append(postprocessed_matrix)\n",
        "postprocessed_original_arr_test = np.array(postprocessed_originals_test)\n",
        "\n",
        "# Postprocess predictions\n",
        "postprocessed_predictions_test = []\n",
        "for i in range(test_prediction_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(test_prediction_original_scale[i])\n",
        "    postprocessed_predictions_test.append(postprocessed_matrix)\n",
        "\n",
        "postprocessed_predictions_arr_test = np.array(postprocessed_predictions_test)\n",
        "\n",
        "# Calcular las mtricas promedio\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(postprocessed_original_arr_train, postprocessed_predictions_arr_train)\n",
        "\n",
        "print(\"Training:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(postprocessed_original_arr_val, postprocessed_predictions_arr_val)\n",
        "\n",
        "print(\"Validation:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(postprocessed_original_arr_test, postprocessed_predictions_arr_test)\n",
        "\n",
        "print(\"Test:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXc8wkPw_awT",
        "outputId": "1a838f90-522c-47ef-9805-a943e92bfc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Average MAE: 1.856\n",
            "Average MSE: 15.271\n",
            "Average RMSE: 3.844\n",
            "Average R^2: 0.925\n",
            "\n",
            "Validation:\n",
            "Average MAE: 2.329\n",
            "Average MSE: 21.874\n",
            "Average RMSE: 4.635\n",
            "Average R^2: 0.913\n",
            "\n",
            "Test:\n",
            "Average MAE: 2.364\n",
            "Average MSE: 22.497\n",
            "Average RMSE: 4.691\n",
            "Average R^2: 0.912\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for 110 coordinates"
      ],
      "metadata": {
        "id": "XWCqTLps_2w3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We convert the data into dataframes and combine actual vs. predictions\n",
        "def array_to_dataframe(arr):\n",
        "    ids = []\n",
        "    is_list = []\n",
        "    js_list = []\n",
        "    velocidades = []\n",
        "\n",
        "    for id in range(arr.shape[0]):\n",
        "        for i in range(arr.shape[1]):\n",
        "            for j in range(arr.shape[2]):\n",
        "                ids.append(id)\n",
        "                is_list.append(i)\n",
        "                js_list.append(j)\n",
        "                velocidades.append(arr[id, i, j])\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'id': ids,\n",
        "        'i': is_list,\n",
        "        'j': js_list,\n",
        "        'speed': velocidades\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "# Training:\n",
        "df_actuals_train = array_to_dataframe(postprocessed_original_arr_train)\n",
        "df_preds_train = array_to_dataframe(postprocessed_predictions_arr_train)\n",
        "\n",
        "df_original_train = df_actuals_train.rename(columns={'speed': 'speed_actual'})\n",
        "df_predictions_train = df_preds_train.rename(columns={'speed': 'speed_predicted'})\n",
        "\n",
        "df_results_train = pd.merge(df_original_train, df_predictions_train, on=['id','i', 'j'], how='inner')\n",
        "# ----------------------------#\n",
        "\n",
        "# Validation:\n",
        "df_actuals_val = array_to_dataframe(postprocessed_original_arr_val)\n",
        "df_preds_val = array_to_dataframe(postprocessed_predictions_arr_val)\n",
        "\n",
        "df_original_val = df_actuals_val.rename(columns={'speed': 'speed_actual'})\n",
        "df_predictions_val = df_preds_val.rename(columns={'speed': 'speed_predicted'})\n",
        "\n",
        "df_results_val = pd.merge(df_original_val, df_predictions_val, on=['id','i', 'j'], how='inner')\n",
        "# ----------------------------#\n",
        "\n",
        "# Test:\n",
        "df_actuals_test = array_to_dataframe(postprocessed_original_arr_test)\n",
        "df_preds_test = array_to_dataframe(postprocessed_predictions_arr_test)\n",
        "\n",
        "df_original_test = df_actuals_test.rename(columns={'speed': 'speed_actual'})\n",
        "df_predictions_test = df_preds_test.rename(columns={'speed': 'speed_predicted'})\n",
        "\n",
        "df_results_test = pd.merge(df_original_test, df_predictions_test, on=['id','i', 'j'], how='inner')\n",
        "# ----------------------------#\n",
        "\n",
        "\n",
        "results_110_train = pd.merge(ori_coords, df_results_train, on=['i','j'])\n",
        "results_110_val = pd.merge(ori_coords, df_results_val, on=['i','j'])\n",
        "results_110_test = pd.merge(ori_coords, df_results_test, on=['i','j'])\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from math import sqrt\n",
        "\n",
        "def calculate_metrics(df):\n",
        "    y_true = df['speed_actual']\n",
        "    y_pred = df['speed_predicted']\n",
        "\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    smape = 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))\n",
        "    maaape = np.mean(np.arctan(np.abs((y_true - y_pred) / y_true))) * 100\n",
        "\n",
        "    return mae, mse, rmse, r2, mape, smape, maaape\n",
        "\n",
        "\n",
        "mae, mse, rmse, r2, mape, smape, maaape = calculate_metrics(results_110_train)\n",
        "\n",
        "print(\"Training:\")\n",
        "print(\"----------\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(f\"Average MAPE: {mape:.3f}\")\n",
        "print(f\"Average SMAPE: {smape:.3f}\")\n",
        "print(f\"Average MAAPE: {maaape:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2, mape, smape, maaape = calculate_metrics(results_110_val)\n",
        "\n",
        "print(\"Validation:\")\n",
        "print(\"----------\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(f\"Average MAPE: {mape:.3f}\")\n",
        "print(f\"Average SMAPE: {smape:.3f}\")\n",
        "print(f\"Average MAAPE: {maaape:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2, mape, smape, maaape = calculate_metrics(results_110_test)\n",
        "\n",
        "print(\"Testing:\")\n",
        "print(\"----------\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(f\"Average MAPE: {mape:.3f}\")\n",
        "print(f\"Average SMAPE: {smape:.3f}\")\n",
        "print(f\"Average MAAPE: {maaape:.3f}\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag4h2kCU_0zh",
        "outputId": "0d9df142-c52a-4211-e21e-728a8043569d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "----------\n",
            "Average MAE: 3.662\n",
            "Average MSE: 30.636\n",
            "Average RMSE: 5.535\n",
            "Average R^2: 0.722\n",
            "Average MAPE: inf\n",
            "Average SMAPE: 15.152\n",
            "Average MAAPE: 15.425\n",
            "\n",
            "Validation:\n",
            "----------\n",
            "Average MAE: 4.575\n",
            "Average MSE: 43.678\n",
            "Average RMSE: 6.609\n",
            "Average R^2: 0.697\n",
            "Average MAPE: inf\n",
            "Average SMAPE: 18.040\n",
            "Average MAAPE: 18.132\n",
            "\n",
            "Testing:\n",
            "----------\n",
            "Average MAE: 4.651\n",
            "Average MSE: 45.083\n",
            "Average RMSE: 6.714\n",
            "Average R^2: 0.694\n",
            "Average MAPE: inf\n",
            "Average SMAPE: 18.330\n",
            "Average MAAPE: 18.490\n",
            "\n"
          ]
        }
      ]
    }
  ]
}