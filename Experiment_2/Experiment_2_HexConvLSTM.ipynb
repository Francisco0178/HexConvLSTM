{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 2:\n",
        "Timestep Reduction to the mean of 3 consecutive hours\n",
        "\n",
        "Network: HexConvLSTM"
      ],
      "metadata": {
        "id": "MOe3D01_b6c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adV_JP_iSXtz",
        "outputId": "41cb0fa5-0c1c-44c8-9e34-8426f8422212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LKjqB17RsAx"
      },
      "outputs": [],
      "source": [
        "# Loading necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(threshold=np.inf, precision=2, linewidth=200)\n",
        "np.set_printoptions(suppress=True, precision=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a first step, we load the raw data from our source."
      ],
      "metadata": {
        "id": "5_cfNVgTSOkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the source path\n",
        "route_folder = \"/content/drive/My Drive/Centro de Transporte/Francisco/2023/Abril 2024/\"\n",
        "\n",
        "# Loading the tensor\n",
        "tensor = np.load(route_folder+'tensor.npy')\n",
        "# 110 original coordinates\n",
        "ori_coords = pd.read_csv(route_folder+'ori_coords.csv')"
      ],
      "metadata": {
        "id": "OcNVmAd4ThkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are going to reduce our time steps by averaging over consecutive 3-hour intervals."
      ],
      "metadata": {
        "id": "_a7WF7mq4NtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if tensor.shape[0] % 3 == 0:\n",
        "    tensor_reshaped = tensor.reshape(-1, 3, tensor.shape[1], tensor.shape[2])\n",
        "    tensor_new = tensor_reshaped.mean(axis=1)"
      ],
      "metadata": {
        "id": "BYPwmKbL9L_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l39NNUci9hOI",
        "outputId": "0f9dbfe8-3f29-44dd-b99b-c3ada50ae845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(628, 44, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have preprocessed our matrices, we will apply min-max scaling normalization to all our steps"
      ],
      "metadata": {
        "id": "uTKzbBZv3UkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "tensor_reshaped = tensor_new.reshape(-1, 15)\n",
        "scaled_tensor = scaler.fit_transform(tensor_reshaped)\n",
        "scaled_tensor = scaled_tensor.reshape(-1, 44, 15)"
      ],
      "metadata": {
        "id": "UDJtPaPO3hhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have normalized our tensor, we divide it into training, validation, and testing sets."
      ],
      "metadata": {
        "id": "z9X6OEIR3sYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_percent = 0.7\n",
        "val_percent = 0.15\n",
        "test_percent = 0.15\n",
        "\n",
        "total_examples = scaled_tensor.shape[0]\n",
        "num_train_examples = int(total_examples * train_percent)\n",
        "num_val_examples = int(total_examples * val_percent)\n",
        "num_test_examples = total_examples - num_train_examples - num_val_examples\n",
        "\n",
        "train_tensor = scaled_tensor[:num_train_examples]\n",
        "val_tensor = scaled_tensor[num_train_examples:num_train_examples+num_val_examples]\n",
        "test_tensor = scaled_tensor[num_train_examples+num_val_examples:]\n",
        "\n",
        "# Add a final dimension of 1 channel; this is necessary to feed it into our network\n",
        "train_tensor = train_tensor.reshape((train_tensor.shape[0], train_tensor.shape[1], train_tensor.shape[2], 1))\n",
        "val_tensor = val_tensor.reshape((val_tensor.shape[0], val_tensor.shape[1], val_tensor.shape[2], 1))\n",
        "test_tensor = test_tensor.reshape((test_tensor.shape[0], test_tensor.shape[1], test_tensor.shape[2], 1))\n",
        "\n",
        "print(train_tensor.shape, val_tensor.shape, test_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBpFWxTv3qv0",
        "outputId": "28c97886-a148-433a-9f46-f122bd290fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(439, 44, 15, 1) (94, 44, 15, 1) (95, 44, 15, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will generate the sequences"
      ],
      "metadata": {
        "id": "GfZTA9Jk4uUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_secuencias(tensor, longitud_secuencia):\n",
        "    secuencias_x = []\n",
        "    secuencias_y = []\n",
        "    for i in range(len(tensor) - longitud_secuencia):\n",
        "        secuencia_x = tensor[i:i+longitud_secuencia]\n",
        "        secuencia_y = tensor[i+longitud_secuencia:i+longitud_secuencia+1]\n",
        "        secuencias_x.append(secuencia_x)\n",
        "        secuencias_y.append(secuencia_y)\n",
        "    return np.array(secuencias_x), np.array(secuencias_y)\n",
        "\n",
        "#  1  2  3   4   5   6   7   8   9   10  11  12\n",
        "# [8][9][10][11][12][13][14][15][16][17][18][19] -> [8]\n",
        "\n",
        "longitud_secuencia = 12\n",
        "\n",
        "x_train, y_train = crear_secuencias(train_tensor, longitud_secuencia)\n",
        "x_val, y_val = crear_secuencias(val_tensor, longitud_secuencia)\n",
        "x_test, y_test = crear_secuencias(test_tensor, longitud_secuencia)\n",
        "\n",
        "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
        "print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))\n",
        "print(\"Validation Dataset Shapes: \" + str(x_test.shape) + \", \" + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvE-iW98381I",
        "outputId": "70996cb3-8fc9-4e6c-e3fd-81d40a10cb3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Shapes: (427, 12, 44, 15, 1), (427, 1, 44, 15, 1)\n",
            "Validation Dataset Shapes: (82, 12, 44, 15, 1), (82, 1, 44, 15, 1)\n",
            "Validation Dataset Shapes: (83, 12, 44, 15, 1), (83, 1, 44, 15, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up to this point, we have preprocessed our tensors and they are ready to be fed into our neural network. But before that, we need to define our hexagonal kernel and our network."
      ],
      "metadata": {
        "id": "KIUUb4Vf47_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define our hexagonal kernel"
      ],
      "metadata": {
        "id": "q6gCWlx35adc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hexagonal kernel\n",
        "class HexConstGrid5x3(tf.keras.constraints.Constraint):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def __call__(self, w):\n",
        "        '''\n",
        "        [[0, 1, 0],\n",
        "         [1, 0, 1],\n",
        "         [0, 1, 0],\n",
        "         [1, 0, 1],\n",
        "         [0, 1, 0]]\n",
        "        '''\n",
        "        hexaconst=np.ones(w.shape,dtype=np.float32)\n",
        "        hexaconst[0,0,:,:]=0.0\n",
        "        hexaconst[0,2,:,:]=0.0\n",
        "        hexaconst[1,1,:,:]=0.0\n",
        "        hexaconst[2,0,:,:]=0.0\n",
        "        hexaconst[2,2,:,:]=0.0\n",
        "        hexaconst[3,1,:,:]=0.0\n",
        "        hexaconst[4,0,:,:]=0.0\n",
        "        hexaconst[4,2,:,:]=0.0\n",
        "\n",
        "        return w*hexaconst"
      ],
      "metadata": {
        "id": "pU5SZekP454d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we define our HexConvLSTM network"
      ],
      "metadata": {
        "id": "dKuKXSPQ5S6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = layers.Input(shape=(None, *x_train.shape[2:]))\n",
        "\n",
        "# ConvLSTM2D layer\n",
        "x = layers.ConvLSTM2D(\n",
        "    filters=128,\n",
        "    kernel_size=(5, 3),\n",
        "    padding=\"same\",\n",
        "    return_sequences=False,\n",
        "    activation=\"relu\",\n",
        "    kernel_constraint=HexConstGrid5x3()\n",
        ")(inp)\n",
        "\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Conv2D layer\n",
        "x = layers.Conv2D(\n",
        "    filters=1,\n",
        "    kernel_size=(3, 3),\n",
        "    activation=\"relu\",\n",
        "    padding=\"same\"\n",
        ")(x)\n",
        "\n",
        "x = layers.Reshape((1,44,15,1))(x)"
      ],
      "metadata": {
        "id": "_Thb-OR-5Sao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the complete model\n",
        "model = keras.models.Model(inp, x)\n",
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer=keras.optimizers.Adam()\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuMqSYrG5h8D",
        "outputId": "8531c901-98b6-4f6a-82ef-c5385d6860e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, 44, 15, 1   0         \n",
            "                             )]                                  \n",
            "                                                                 \n",
            " conv_lstm2d (ConvLSTM2D)    (None, 44, 15, 128)       991232    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 44, 15, 128)       512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 44, 15, 1)         1153      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 44, 15, 1)      0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 992897 (3.79 MB)\n",
            "Trainable params: 992641 (3.79 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our network defined, let's train it."
      ],
      "metadata": {
        "id": "O7WzcmQF5nHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some callbacks to improve training.\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
        "\n",
        "# Define modifiable training hyperparameters.\n",
        "epochs = 500\n",
        "batch_size = 64\n",
        "\n",
        "# Fit the model to the training data.\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BxawDce5lbB",
        "outputId": "61e6dbb0-ddb4-4cdf-f170-4ea22d81370a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "7/7 [==============================] - 11s 373ms/step - loss: 0.1475 - val_loss: 0.0774 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.0146 - val_loss: 0.0748 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0055 - val_loss: 0.0727 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0039 - val_loss: 0.0740 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "7/7 [==============================] - 2s 266ms/step - loss: 0.0031 - val_loss: 0.0715 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "7/7 [==============================] - 2s 268ms/step - loss: 0.0028 - val_loss: 0.0720 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0026 - val_loss: 0.0706 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0025 - val_loss: 0.0705 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.0025 - val_loss: 0.0701 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0024 - val_loss: 0.0699 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0024 - val_loss: 0.0697 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0024 - val_loss: 0.0693 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "7/7 [==============================] - 2s 273ms/step - loss: 0.0024 - val_loss: 0.0691 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0023 - val_loss: 0.0691 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0023 - val_loss: 0.0689 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0023 - val_loss: 0.0685 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0023 - val_loss: 0.0684 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0023 - val_loss: 0.0683 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0023 - val_loss: 0.0681 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "7/7 [==============================] - 2s 265ms/step - loss: 0.0022 - val_loss: 0.0678 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "7/7 [==============================] - 2s 265ms/step - loss: 0.0022 - val_loss: 0.0675 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0673 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0671 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0022 - val_loss: 0.0669 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0662 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0022 - val_loss: 0.0660 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "7/7 [==============================] - 2s 268ms/step - loss: 0.0022 - val_loss: 0.0655 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "7/7 [==============================] - 2s 269ms/step - loss: 0.0022 - val_loss: 0.0650 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0649 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0022 - val_loss: 0.0641 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0635 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0630 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0624 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0022 - val_loss: 0.0624 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0022 - val_loss: 0.0616 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0022 - val_loss: 0.0608 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "7/7 [==============================] - 2s 271ms/step - loss: 0.0022 - val_loss: 0.0603 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "7/7 [==============================] - 2s 276ms/step - loss: 0.0022 - val_loss: 0.0599 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "7/7 [==============================] - 2s 266ms/step - loss: 0.0022 - val_loss: 0.0590 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "7/7 [==============================] - 2s 268ms/step - loss: 0.0022 - val_loss: 0.0586 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "7/7 [==============================] - 2s 268ms/step - loss: 0.0022 - val_loss: 0.0571 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "7/7 [==============================] - 2s 269ms/step - loss: 0.0022 - val_loss: 0.0575 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0022 - val_loss: 0.0559 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0022 - val_loss: 0.0557 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0542 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0547 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0022 - val_loss: 0.0539 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0022 - val_loss: 0.0527 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "7/7 [==============================] - 2s 268ms/step - loss: 0.0022 - val_loss: 0.0519 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0022 - val_loss: 0.0514 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0499 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0498 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0479 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0470 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0022 - val_loss: 0.0475 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "7/7 [==============================] - 2s 269ms/step - loss: 0.0022 - val_loss: 0.0462 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "7/7 [==============================] - 2s 269ms/step - loss: 0.0022 - val_loss: 0.0441 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0440 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0435 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0022 - val_loss: 0.0416 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0404 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0022 - val_loss: 0.0406 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "7/7 [==============================] - 2s 270ms/step - loss: 0.0022 - val_loss: 0.0391 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0022 - val_loss: 0.0374 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0022 - val_loss: 0.0376 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0361 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0332 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "7/7 [==============================] - 2s 281ms/step - loss: 0.0022 - val_loss: 0.0332 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "7/7 [==============================] - 2s 293ms/step - loss: 0.0022 - val_loss: 0.0331 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "7/7 [==============================] - 2s 270ms/step - loss: 0.0022 - val_loss: 0.0331 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "7/7 [==============================] - 2s 266ms/step - loss: 0.0022 - val_loss: 0.0309 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.0021 - val_loss: 0.0295 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0286 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0272 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0269 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0022 - val_loss: 0.0272 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "7/7 [==============================] - 2s 265ms/step - loss: 0.0022 - val_loss: 0.0254 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "7/7 [==============================] - 2s 273ms/step - loss: 0.0022 - val_loss: 0.0220 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0022 - val_loss: 0.0221 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0212 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0201 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0194 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0193 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0185 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0177 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0022 - val_loss: 0.0150 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0022 - val_loss: 0.0158 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0152 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0128 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0124 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0021 - val_loss: 0.0122 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "7/7 [==============================] - 2s 273ms/step - loss: 0.0021 - val_loss: 0.0118 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0116 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0097 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0097 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0098 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0090 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0078 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "7/7 [==============================] - 2s 269ms/step - loss: 0.0021 - val_loss: 0.0079 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0021 - val_loss: 0.0075 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0021 - val_loss: 0.0072 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0067 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0059 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0058 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0060 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0021 - val_loss: 0.0059 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0048 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0051 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0056 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0022 - val_loss: 0.0045 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0038 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0022 - val_loss: 0.0042 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "7/7 [==============================] - 2s 266ms/step - loss: 0.0021 - val_loss: 0.0045 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "7/7 [==============================] - 2s 275ms/step - loss: 0.0021 - val_loss: 0.0041 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.0021 - val_loss: 0.0037 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0040 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0038 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0037 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0037 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "7/7 [==============================] - 2s 270ms/step - loss: 0.0021 - val_loss: 0.0035 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0036 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0035 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0034 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0034 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0033 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "7/7 [==============================] - 2s 266ms/step - loss: 0.0021 - val_loss: 0.0033 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0021 - val_loss: 0.0033 - lr: 1.0000e-04\n",
            "Epoch 128/500\n",
            "7/7 [==============================] - 2s 269ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 129/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0021 - val_loss: 0.0033 - lr: 1.0000e-04\n",
            "Epoch 130/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 131/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 132/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 133/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
            "Epoch 134/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-05\n",
            "Epoch 135/500\n",
            "7/7 [==============================] - 2s 266ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-05\n",
            "Epoch 136/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-05\n",
            "Epoch 137/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-05\n",
            "Epoch 138/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-05\n",
            "Epoch 139/500\n",
            "7/7 [==============================] - 2s 266ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 140/500\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 141/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 142/500\n",
            "7/7 [==============================] - 2s 265ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 143/500\n",
            "7/7 [==============================] - 2s 273ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 144/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 145/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-06\n",
            "Epoch 146/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 147/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 148/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 149/500\n",
            "7/7 [==============================] - 2s 266ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 150/500\n",
            "7/7 [==============================] - 2s 268ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-07\n",
            "Epoch 151/500\n",
            "7/7 [==============================] - 2s 266ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 152/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 153/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 154/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 155/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-08\n",
            "Epoch 156/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 157/500\n",
            "7/7 [==============================] - 2s 265ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 158/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 159/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 160/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-09\n",
            "Epoch 161/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 162/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 163/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 164/500\n",
            "7/7 [==============================] - 2s 269ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 165/500\n",
            "7/7 [==============================] - 2s 268ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-10\n",
            "Epoch 166/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 167/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 168/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 169/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 170/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-11\n",
            "Epoch 171/500\n",
            "7/7 [==============================] - 2s 270ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 172/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 173/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 174/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 175/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-12\n",
            "Epoch 176/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 177/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 178/500\n",
            "7/7 [==============================] - 2s 270ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 179/500\n",
            "7/7 [==============================] - 2s 269ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 180/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-13\n",
            "Epoch 181/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 182/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 183/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 184/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 185/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-14\n",
            "Epoch 186/500\n",
            "7/7 [==============================] - 2s 270ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 187/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 188/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 189/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 190/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-15\n",
            "Epoch 191/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 192/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 193/500\n",
            "7/7 [==============================] - 2s 266ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 194/500\n",
            "7/7 [==============================] - 2s 268ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 195/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-16\n",
            "Epoch 196/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 197/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 198/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 199/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 200/500\n",
            "7/7 [==============================] - 2s 272ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-17\n",
            "Epoch 201/500\n",
            "7/7 [==============================] - 2s 268ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 202/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 203/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 204/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 205/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-18\n",
            "Epoch 206/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 207/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 208/500\n",
            "7/7 [==============================] - 2s 269ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 209/500\n",
            "7/7 [==============================] - 2s 266ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 210/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-19\n",
            "Epoch 211/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 212/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 213/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 214/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 215/500\n",
            "7/7 [==============================] - 2s 272ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-20\n",
            "Epoch 216/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-21\n",
            "Epoch 217/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-21\n",
            "Epoch 218/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-21\n",
            "Epoch 219/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-21\n",
            "Epoch 220/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-21\n",
            "Epoch 221/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-22\n",
            "Epoch 222/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-22\n",
            "Epoch 223/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-22\n",
            "Epoch 224/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-22\n",
            "Epoch 225/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-22\n",
            "Epoch 226/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-23\n",
            "Epoch 227/500\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-23\n",
            "Epoch 228/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-23\n",
            "Epoch 229/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-23\n",
            "Epoch 230/500\n",
            "7/7 [==============================] - 2s 267ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-23\n",
            "Epoch 231/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-24\n",
            "Epoch 232/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-24\n",
            "Epoch 233/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-24\n",
            "Epoch 234/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-24\n",
            "Epoch 235/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-24\n",
            "Epoch 236/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-25\n",
            "Epoch 237/500\n",
            "7/7 [==============================] - 2s 271ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-25\n",
            "Epoch 238/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-25\n",
            "Epoch 239/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-25\n",
            "Epoch 240/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-25\n",
            "Epoch 241/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-26\n",
            "Epoch 242/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-26\n",
            "Epoch 243/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-26\n",
            "Epoch 244/500\n",
            "7/7 [==============================] - 2s 269ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-26\n",
            "Epoch 245/500\n",
            "7/7 [==============================] - 2s 265ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-26\n",
            "Epoch 246/500\n",
            "7/7 [==============================] - 2s 264ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-27\n",
            "Epoch 247/500\n",
            "7/7 [==============================] - 2s 262ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-27\n",
            "Epoch 248/500\n",
            "7/7 [==============================] - 2s 261ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-27\n",
            "Epoch 249/500\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-27\n",
            "Epoch 250/500\n",
            "7/7 [==============================] - 2s 263ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 1.0000e-27\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79e20bd35120>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the loss"
      ],
      "metadata": {
        "id": "N0XtKp9s-P5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.history.history\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['loss'], label='Training Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "U-GB3gjO5ujD",
        "outputId": "2c0d3788-b754-4648-86e6-9466626324c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's generate the evaluation metrics for the dimensions 44x15, 15x15, and the 110 coordinates."
      ],
      "metadata": {
        "id": "iNovqiYT-jGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_prediction = model.predict(x_train)\n",
        "train_prediction.shape\n",
        "\n",
        "train_prediction_reshaped = train_prediction.reshape(-1, 15)\n",
        "train_prediction_original_scale = scaler.inverse_transform(train_prediction_reshaped)\n",
        "train_prediction_original_scale = train_prediction_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "y_train_reshaped = y_train.reshape(-1, 15)\n",
        "y_train_original_scale = scaler.inverse_transform(y_train_reshaped)\n",
        "y_train_original_scale = y_train_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "val_prediction = model.predict(x_val)\n",
        "\n",
        "val_prediction_reshaped = val_prediction.reshape(-1, 15)\n",
        "val_prediction_original_scale = scaler.inverse_transform(val_prediction_reshaped)\n",
        "val_prediction_original_scale = val_prediction_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "y_val_reshaped = y_val.reshape(-1, 15)\n",
        "y_val_original_scale = scaler.inverse_transform(y_val_reshaped)\n",
        "y_val_original_scale = y_val_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "test_prediction = model.predict(x_test)\n",
        "\n",
        "test_prediction_reshaped = test_prediction.reshape(-1, 15)\n",
        "test_prediction_original_scale = scaler.inverse_transform(test_prediction_reshaped)\n",
        "test_prediction_original_scale = test_prediction_original_scale.reshape(-1, 44, 15)\n",
        "\n",
        "y_test_reshaped = y_test.reshape(-1, 15)\n",
        "y_test_original_scale = scaler.inverse_transform(y_test_reshaped)\n",
        "y_test_original_scale = y_test_original_scale.reshape(-1, 44, 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIX-v5Tn-VYJ",
        "outputId": "d91dd749-6e1a-44f4-967e-df91032e8149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 1s 52ms/step\n",
            "3/3 [==============================] - 0s 44ms/step\n",
            "3/3 [==============================] - 0s 104ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def calcular_metricas_3d(original_tensor, prediccion_tensor):\n",
        "\n",
        "    sum_mae, sum_mse, sum_rmse, sum_r2 = 0, 0, 0, 0\n",
        "\n",
        "    for i in range(original_tensor.shape[0]):\n",
        "        mae = mean_absolute_error(original_tensor[i], prediccion_tensor[i])\n",
        "        mse = mean_squared_error(original_tensor[i], prediccion_tensor[i])\n",
        "        rmse = np.sqrt(mse)\n",
        "        r2 = r2_score(original_tensor[i].flatten(), prediccion_tensor[i].flatten())\n",
        "\n",
        "        sum_mae += mae\n",
        "        sum_mse += mse\n",
        "        sum_rmse += rmse\n",
        "        sum_r2 += r2\n",
        "\n",
        "    avg_mae = sum_mae / original_tensor.shape[0]\n",
        "    avg_mse = sum_mse / original_tensor.shape[0]\n",
        "    avg_rmse = sum_rmse / original_tensor.shape[0]\n",
        "    avg_r2 = sum_r2 / original_tensor.shape[0]\n",
        "\n",
        "    return avg_mae, avg_mse, avg_rmse, avg_r2"
      ],
      "metadata": {
        "id": "ATmsGRat_EWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for 44x15"
      ],
      "metadata": {
        "id": "FR2WvelW_MOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae, mse, rmse, r2 = calcular_metricas_3d(y_train_original_scale, train_prediction_original_scale)\n",
        "\n",
        "print(\"Training:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(y_val_original_scale, val_prediction_original_scale)\n",
        "\n",
        "print(\"Validation:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(y_test_original_scale, test_prediction_original_scale)\n",
        "\n",
        "print(\"Test:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCkjRYsc_K7r",
        "outputId": "19674ccb-8201-4356-9389-d8e11d5e413d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Average MAE: 1.268\n",
            "Average MSE: 10.419\n",
            "Average RMSE: 3.175\n",
            "Average R^2: 0.941\n",
            "\n",
            "Validation:\n",
            "Average MAE: 1.599\n",
            "Average MSE: 15.175\n",
            "Average RMSE: 3.859\n",
            "Average R^2: 0.931\n",
            "\n",
            "Test:\n",
            "Average MAE: 1.620\n",
            "Average MSE: 15.493\n",
            "Average RMSE: 3.895\n",
            "Average R^2: 0.930\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for 15x15"
      ],
      "metadata": {
        "id": "j-MP14If_f4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess(arr):\n",
        "  unshifted_matrix = np.empty_like(arr)\n",
        "  for i in range(arr.shape[1]):\n",
        "      n = i\n",
        "      unshifted_matrix[:, i] = np.concatenate((arr[-n:, i], arr[:-n, i]))\n",
        "\n",
        "  unpadded_matrix = unshifted_matrix[14:, :]\n",
        "  downsampled_matrix = unpadded_matrix[::2]\n",
        "\n",
        "  return downsampled_matrix\n",
        "\n",
        "# Training:\n",
        "# Postprocess originals\n",
        "postprocessed_originals_train = []\n",
        "for i in range(y_train_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(y_train_original_scale[i])\n",
        "    postprocessed_originals_train.append(postprocessed_matrix)\n",
        "postprocessed_original_arr_train = np.array(postprocessed_originals_train)\n",
        "\n",
        "# Postprocess predictions\n",
        "postprocessed_predictions_train = []\n",
        "for i in range(train_prediction_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(train_prediction_original_scale[i])\n",
        "    postprocessed_predictions_train.append(postprocessed_matrix)\n",
        "\n",
        "postprocessed_predictions_arr_train = np.array(postprocessed_predictions_train)\n",
        "\n",
        "# Validation:\n",
        "# Postprocess originals\n",
        "postprocessed_originals_val = []\n",
        "for i in range(y_val_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(y_val_original_scale[i])\n",
        "    postprocessed_originals_val.append(postprocessed_matrix)\n",
        "postprocessed_original_arr_val = np.array(postprocessed_originals_val)\n",
        "\n",
        "# Postprocess predictions\n",
        "postprocessed_predictions_val = []\n",
        "for i in range(val_prediction_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(val_prediction_original_scale[i])\n",
        "    postprocessed_predictions_val.append(postprocessed_matrix)\n",
        "\n",
        "postprocessed_predictions_arr_val = np.array(postprocessed_predictions_val)\n",
        "\n",
        "# Testing:\n",
        "# Postprocess originals\n",
        "postprocessed_originals_test = []\n",
        "for i in range(y_test_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(y_test_original_scale[i])\n",
        "    postprocessed_originals_test.append(postprocessed_matrix)\n",
        "postprocessed_original_arr_test = np.array(postprocessed_originals_test)\n",
        "\n",
        "# Postprocess predictions\n",
        "postprocessed_predictions_test = []\n",
        "for i in range(test_prediction_original_scale.shape[0]):\n",
        "    postprocessed_matrix = postprocess(test_prediction_original_scale[i])\n",
        "    postprocessed_predictions_test.append(postprocessed_matrix)\n",
        "\n",
        "postprocessed_predictions_arr_test = np.array(postprocessed_predictions_test)\n",
        "\n",
        "# Calcular las mtricas promedio\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(postprocessed_original_arr_train, postprocessed_predictions_arr_train)\n",
        "\n",
        "print(\"Training:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(postprocessed_original_arr_val, postprocessed_predictions_arr_val)\n",
        "\n",
        "print(\"Validation:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2 = calcular_metricas_3d(postprocessed_original_arr_test, postprocessed_predictions_arr_test)\n",
        "\n",
        "print(\"Test:\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXc8wkPw_awT",
        "outputId": "8b6ce67a-ab8a-44d0-ca2c-441ebb67f4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Average MAE: 1.859\n",
            "Average MSE: 15.281\n",
            "Average RMSE: 3.845\n",
            "Average R^2: 0.925\n",
            "\n",
            "Validation:\n",
            "Average MAE: 2.348\n",
            "Average MSE: 22.319\n",
            "Average RMSE: 4.681\n",
            "Average R^2: 0.912\n",
            "\n",
            "Test:\n",
            "Average MAE: 2.377\n",
            "Average MSE: 22.739\n",
            "Average RMSE: 4.717\n",
            "Average R^2: 0.911\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for 110 coordinates"
      ],
      "metadata": {
        "id": "XWCqTLps_2w3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We convert the data into dataframes and combine actual vs. predictions\n",
        "def array_to_dataframe(arr):\n",
        "    ids = []\n",
        "    is_list = []\n",
        "    js_list = []\n",
        "    velocidades = []\n",
        "\n",
        "    for id in range(arr.shape[0]):\n",
        "        for i in range(arr.shape[1]):\n",
        "            for j in range(arr.shape[2]):\n",
        "                ids.append(id)\n",
        "                is_list.append(i)\n",
        "                js_list.append(j)\n",
        "                velocidades.append(arr[id, i, j])\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'id': ids,\n",
        "        'i': is_list,\n",
        "        'j': js_list,\n",
        "        'speed': velocidades\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "# Training:\n",
        "df_actuals_train = array_to_dataframe(postprocessed_original_arr_train)\n",
        "df_preds_train = array_to_dataframe(postprocessed_predictions_arr_train)\n",
        "\n",
        "df_original_train = df_actuals_train.rename(columns={'speed': 'speed_actual'})\n",
        "df_predictions_train = df_preds_train.rename(columns={'speed': 'speed_predicted'})\n",
        "\n",
        "df_results_train = pd.merge(df_original_train, df_predictions_train, on=['id','i', 'j'], how='inner')\n",
        "# ----------------------------#\n",
        "\n",
        "# Validation:\n",
        "df_actuals_val = array_to_dataframe(postprocessed_original_arr_val)\n",
        "df_preds_val = array_to_dataframe(postprocessed_predictions_arr_val)\n",
        "\n",
        "df_original_val = df_actuals_val.rename(columns={'speed': 'speed_actual'})\n",
        "df_predictions_val = df_preds_val.rename(columns={'speed': 'speed_predicted'})\n",
        "\n",
        "df_results_val = pd.merge(df_original_val, df_predictions_val, on=['id','i', 'j'], how='inner')\n",
        "# ----------------------------#\n",
        "\n",
        "# Test:\n",
        "df_actuals_test = array_to_dataframe(postprocessed_original_arr_test)\n",
        "df_preds_test = array_to_dataframe(postprocessed_predictions_arr_test)\n",
        "\n",
        "df_original_test = df_actuals_test.rename(columns={'speed': 'speed_actual'})\n",
        "df_predictions_test = df_preds_test.rename(columns={'speed': 'speed_predicted'})\n",
        "\n",
        "df_results_test = pd.merge(df_original_test, df_predictions_test, on=['id','i', 'j'], how='inner')\n",
        "# ----------------------------#\n",
        "\n",
        "\n",
        "results_110_train = pd.merge(ori_coords, df_results_train, on=['i','j'])\n",
        "results_110_val = pd.merge(ori_coords, df_results_val, on=['i','j'])\n",
        "results_110_test = pd.merge(ori_coords, df_results_test, on=['i','j'])\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from math import sqrt\n",
        "\n",
        "def calculate_metrics(df):\n",
        "    y_true = df['speed_actual']\n",
        "    y_pred = df['speed_predicted']\n",
        "\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    smape = 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))\n",
        "    maaape = np.mean(np.arctan(np.abs((y_true - y_pred) / y_true))) * 100\n",
        "\n",
        "    return mae, mse, rmse, r2, mape, smape, maaape\n",
        "\n",
        "\n",
        "mae, mse, rmse, r2, mape, smape, maaape = calculate_metrics(results_110_train)\n",
        "\n",
        "print(\"Training:\")\n",
        "print(\"----------\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(f\"Average MAPE: {mape:.3f}\")\n",
        "print(f\"Average SMAPE: {smape:.3f}\")\n",
        "print(f\"Average MAAPE: {maaape:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2, mape, smape, maaape = calculate_metrics(results_110_val)\n",
        "\n",
        "print(\"Validation:\")\n",
        "print(\"----------\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(f\"Average MAPE: {mape:.3f}\")\n",
        "print(f\"Average SMAPE: {smape:.3f}\")\n",
        "print(f\"Average MAAPE: {maaape:.3f}\")\n",
        "print(\"\")\n",
        "\n",
        "mae, mse, rmse, r2, mape, smape, maaape = calculate_metrics(results_110_test)\n",
        "\n",
        "print(\"Testing:\")\n",
        "print(\"----------\")\n",
        "print(f\"Average MAE: {mae:.3f}\")\n",
        "print(f\"Average MSE: {mse:.3f}\")\n",
        "print(f\"Average RMSE: {rmse:.3f}\")\n",
        "print(f\"Average R^2: {r2:.3f}\")\n",
        "print(f\"Average MAPE: {mape:.3f}\")\n",
        "print(f\"Average SMAPE: {smape:.3f}\")\n",
        "print(f\"Average MAAPE: {maaape:.3f}\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag4h2kCU_0zh",
        "outputId": "22877dee-2fc3-4507-b750-1a8bfab8bbf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "----------\n",
            "Average MAE: 3.664\n",
            "Average MSE: 30.650\n",
            "Average RMSE: 5.536\n",
            "Average R^2: 0.720\n",
            "Average MAPE: inf\n",
            "Average SMAPE: 15.327\n",
            "Average MAAPE: 15.575\n",
            "\n",
            "Validation:\n",
            "----------\n",
            "Average MAE: 4.605\n",
            "Average MSE: 44.645\n",
            "Average RMSE: 6.682\n",
            "Average R^2: 0.691\n",
            "Average MAPE: inf\n",
            "Average SMAPE: 18.138\n",
            "Average MAAPE: 18.212\n",
            "\n",
            "Testing:\n",
            "----------\n",
            "Average MAE: 4.647\n",
            "Average MSE: 45.512\n",
            "Average RMSE: 6.746\n",
            "Average R^2: 0.691\n",
            "Average MAPE: inf\n",
            "Average SMAPE: 18.504\n",
            "Average MAAPE: 18.630\n",
            "\n"
          ]
        }
      ]
    }
  ]
}